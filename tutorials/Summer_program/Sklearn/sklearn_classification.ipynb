{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn packages\n",
    "\n",
    "- sklearn套件是專門針對機器學習設計的套件\n",
    "- 功能包含資料前處理、建立各類模型、計算評估指標\n",
    "- sklearn主要接受的資料格式為numpy.ndarray，但由於pandas資料表格式也與numpy相容因此可通用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這次我們嘗試著整理比較複雜的資料，除了直接預測模型之外也加入一些前處理的步驟"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "https://www.kaggle.com/c/titanic/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dat = pd.read_csv('titanic/train.csv')\n",
    "test_dat = pd.read_csv('titanic/test.csv')\n",
    "\n",
    "print(train_dat.shape)\n",
    "print(test_dat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dat.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dat = pd.concat([train_dat, test_dat], sort = False)\n",
    "full_dat.reset_index(drop = True, inplace = True)\n",
    "\n",
    "full_dat.drop(['Name', 'Ticket', 'Cabin', 'PassengerId'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess\n",
    "- missing imputation\n",
    "- one-hot / label encoding\n",
    "- normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### missing imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dat.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing imputation\n",
    "\n",
    "full_dat['Age'].fillna(full_dat['Age'].median(), inplace = True)\n",
    "full_dat['Embarked'].fillna(full_dat['Embarked'].mode()[0], inplace = True)\n",
    "full_dat['Fare'].fillna(full_dat['Fare'].median(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dat.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding\n",
    "\n",
    "one_hot_dat = pd.get_dummies(full_dat, columns = ['Pclass','Sex','Embarked'])\n",
    "one_hot_dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import OneHotEncoder (個人覺得不好用)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "fdat_cp = full_dat.copy()\n",
    "\n",
    "for col in ['Pclass','Sex','Embarked']:\n",
    "    fdat_cp[col] = LabelEncoder().fit_transform(fdat_cp[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_columns = OneHotEncoder(sparse = False).fit_transform(fdat_cp[['Pclass','Sex','Embarked']])\n",
    "\n",
    "one_hot_columns[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdat_cp[['Pclass','Sex','Embarked']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std_s = StandardScaler()\n",
    "\n",
    "survived_ = one_hot_dat['Survived']\n",
    "one_hot_dat.drop('Survived', axis = 1, inplace = True)\n",
    "\n",
    "normalize_dat = std_s.fit_transform(one_hot_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(normalize_dat))\n",
    "print(normalize_dat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_dat.sum(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_index = survived_.isna()\n",
    "\n",
    "train_x = normalize_dat[~test_index]\n",
    "test_x = normalize_dat[test_index]\n",
    "train_y = survived_[~test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_x, v_x, t_y, v_y = train_test_split(train_x, train_y, test_size = 0.2, shuffle = True, random_state = 412)\n",
    "\n",
    "print(t_x.shape)\n",
    "print(v_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(t_x, t_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('training score (decision tree : {:.3f}'.format(dt_model.score(t_x, t_y)))\n",
    "print('validation score (decision tree : {:.3f}'.format(dt_model.score(v_x, v_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_true = v_y, y_pred = dt_model.predict(v_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction = dt_model.predict(test_x)\n",
    "test_dat['Survived'] = test_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dat.to_csv('titanic_prediction.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 練習時間\n",
    "\n",
    "請使用不同模型預測titanic資料集中的乘客存活與否，並看一下結果是否比決策樹還要來得好？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code starts from here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 監督式學習2.0\n",
    "\n",
    "做完以上的範例與練習，希望大家能夠\n",
    "\n",
    "- 進行基本的資料前處理動作\n",
    "- 能夠比較不同的模型效果"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
