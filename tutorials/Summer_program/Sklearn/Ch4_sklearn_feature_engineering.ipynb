{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn - Feature Engineering\n",
    "\n",
    "In this tutorial, we try to do extra feature engineering and figure out which features are important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_dat = pd.read_csv('titanic/train.csv')\n",
    "test_dat = pd.read_csv('titanic/test.csv')\n",
    "\n",
    "full_dat = pd.concat([train_dat, test_dat], sort = False)\n",
    "full_dat.reset_index(drop = True, inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['PassengerId', 'Age', 'Fare']:\n",
    "    sns.violinplot(full_dat['Survived'], full_dat[col])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked']:\n",
    "    sns.barplot(full_dat[col], full_dat['Survived'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dat.Cabin.value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dat.Ticket.value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- categorical variable\n",
    "    - **PassengerId** : delete\n",
    "    - **Name** : delete\n",
    "    - **Ticket** : delete\n",
    "\n",
    "    - **Cabin** : select cabin title(alphabet) as categorical feature\n",
    "    - **Pclass** : one-hot encoding\n",
    "    - **Sex** : one-hot encoding\n",
    "    - **Embarked** : one-hot encoding\n",
    "\n",
    "\n",
    "- continuous variable\n",
    "\n",
    "    - **Survived** : predictive variable\n",
    "    - **Age** : impute missing value with mean age group by port-embarked, Pclass, and Sex\n",
    "    - **Fare** : impute missing value with median of total Fare, and generate new feature called Fare-bin\n",
    "    - **SibSp** : generate new feature by computing sum of SibSp and Parch\n",
    "    - **Parch** : generate new feature by computing sum of SibSp and Parch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing imputation---#\n",
    "full_dat['Embarked'].fillna(full_dat['Embarked'].mode()[0], inplace = True)\n",
    "full_dat['Fare'].fillna(full_dat['Fare'].median(), inplace = True)\n",
    "\n",
    "full_dat['Age'] = full_dat.groupby(['Pclass', 'Sex', 'Embarked'])['Age'].apply(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new feature : Family size\n",
    "full_dat['Family_size'] = full_dat.SibSp+full_dat.Parch+1\n",
    "\n",
    "\n",
    "# new feature : Fare_bin\n",
    "full_dat['Fare_bin'] = pd.qcut(full_dat['Fare'], 5)\n",
    "\n",
    "\n",
    "# new feature : Cabin group\n",
    "full_dat['Cabin_group'] = full_dat.Cabin.fillna('Z').apply(lambda x: x[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns---#\n",
    "full_dat.drop(['Name', 'Ticket', 'Cabin', 'PassengerId', 'Fare'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encoding---#\n",
    "one_hot_dat = pd.get_dummies(full_dat, columns = ['Pclass','Sex','Embarked','Fare_bin','Cabin_group'])\n",
    "one_hot_dat.head()\n",
    "\n",
    "\n",
    "#normalization---#\n",
    "std_s = StandardScaler()\n",
    "\n",
    "survived_ = one_hot_dat['Survived']\n",
    "one_hot_dat.drop('Survived', axis = 1, inplace = True)\n",
    "\n",
    "normalize_dat = std_s.fit_transform(one_hot_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split---#\n",
    "test_index = survived_.isna()\n",
    "\n",
    "train_x = normalize_dat[~test_index]\n",
    "test_x = normalize_dat[test_index]\n",
    "train_y = survived_[~test_index]\n",
    "\n",
    "t_x, v_x, t_y, v_y = train_test_split(train_x, train_y, test_size = 0.2, shuffle = True, random_state = 412)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(t_x, t_y)\n",
    "\n",
    "print('training score (decision tree : {:.3f}'.format(dt_model.score(t_x, t_y)))\n",
    "print('validation score (decision tree : {:.3f}'.format(dt_model.score(v_x, v_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_true = v_y, y_pred = dt_model.predict(v_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c,i in zip(one_hot_dat.columns, dt_model.feature_importances_):\n",
    "    print('{}:{:.3f}'.format(c,i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervise learning 4.0\n",
    "\n",
    "After the exmaple and practice, you should be able to\n",
    "\n",
    "- know how create features / do feature engineering\n",
    "- use feature importance on tree-based model to investigate which features are useful\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
